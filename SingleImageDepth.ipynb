{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SingleImageDepth.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhM9xeyFn8t2"
      },
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Concatenate, Reshape\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.optimizers import SGD, Nadam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegZCVwr0RJf"
      },
      "source": [
        "# Broken dataset link: https://drive.google.com/drive/folders/1IRhybT-PCuwD3pIvzRMxuEByA7p5Iz4K?usp=sharing\n",
        "# Train & test dataset link: https://drive.google.com/drive/folders/1zWYJvkjkiBbfQuTBSTp3Btk-m8uGiSwN?usp=sharing\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHQaZV08ITIJ"
      },
      "source": [
        "x = glob.glob(\"/content/gdrive/MyDrive/*/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzpyxv04hb_u"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "import time\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 30%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bbn6CSa0iVJ"
      },
      "source": [
        "def read_and_resize(filename: str, grayscale: bool = False, fx: float = 1.0, fy: float = 1.0):\n",
        "    if grayscale:\n",
        "        img_result = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        imgbgr = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
        "        # convert to rgb\n",
        "        img_result = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
        "    # resize\n",
        "    if fx != 1.0 and fy != 1.0:\n",
        "        img_result = cv2.resize(img_result, None, fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)\n",
        "    return img_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSaGa_-Q0kVY"
      },
      "source": [
        "def show_in_row(list_of_images: list, titles: list = None, disable_ticks: bool = False):\n",
        "    count = len(list_of_images)\n",
        "    for idx in range(count):\n",
        "        subplot = plt.subplot(1, count, idx + 1)\n",
        "        if titles is not None:\n",
        "            subplot.set_title(titles[idx])\n",
        "\n",
        "        img = list_of_images[idx]\n",
        "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
        "        subplot.imshow(img, cmap=cmap)\n",
        "        if disable_ticks:\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvfN5mBx0XYw"
      },
      "source": [
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcP3PDq60ZM3"
      },
      "source": [
        "def natural_keys(text):\n",
        "    '''\n",
        "    alist.sort(key=natural_keys) sorts in human order\n",
        "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
        "    (See Toothy's implementation in the comments)\n",
        "    '''\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS1Db62w0GLV"
      },
      "source": [
        "def make_model():\n",
        "    # coarse branch\n",
        "    in_coarse = Input(shape=(240, 320, 3))\n",
        "    c1 = Conv2D(filters=96, kernel_size=15, strides=5, activation='tanh')(in_coarse)\n",
        "    c2 = MaxPool2D(pool_size=2, strides=1)(c1)\n",
        "    c3 = Conv2D(filters=128, kernel_size=5, strides=3, activation='tanh')(c2)\n",
        "    c4 = Conv2D(filters=128, kernel_size=3, strides=1, activation='tanh')(c3)\n",
        "    c5 = Conv2D(filters=64, kernel_size=3, strides=1, activation='tanh')(c4)\n",
        "    c6 = Flatten()(c5)\n",
        "    c7 = Dense(5120, activation='tanh')(c6)\n",
        "    c8 = Dense(4800)(c7)\n",
        "    c9 = Reshape((60, 80, 1), input_shape=(4800,), name=\"coarse_out\")(c8)\n",
        "\n",
        "    # fine branch\n",
        "    in_shape_fine = Input(shape=(240, 320, 3))\n",
        "    f1 = Conv2D(filters=59, kernel_size=5, strides=2, padding=\"same\", activation='tanh')(in_shape_fine)\n",
        "    f2 = MaxPool2D(pool_size=2, name=\"fine_pool\")(f1)\n",
        "    f3 = Concatenate(axis=-1)([f2, c9])\n",
        "    f4 = Conv2D(filters=60, kernel_size=5, strides=2,  padding=\"same\", activation='tanh')(f3)\n",
        "    f5 = Conv2D(filters=1, kernel_size=3, padding=\"same\", name=\"Fine_out\")(f4)\n",
        "\n",
        "    model = Model(inputs=[in_coarse, in_shape_fine], outputs=f5, name=\"CF_model\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OZ0eDqbOvE"
      },
      "source": [
        "dirs = glob.glob(\"/content/gdrive/MyDrive/DATASET/Train/Images/*/\")\n",
        "\n",
        "# model = make_model()\n",
        "model = load_model('/content/gdrive/MyDrive/Model/CF_model.h5')\n",
        "dirs.sort(key=natural_keys)\n",
        "'''\n",
        "broken folders:\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/basements/basement_0001c/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/bathrooms_part1/bathroom_0002/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0002/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0006/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0010/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0011/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0013/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/dining_rooms_part1/dining_room_0017/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/libraries/library_0004/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/study_rooms/study_room_0001/\n",
        "/content/gdrive/MyDrive/DATASET_BROKEN/Train/Images/study_rooms/study_room_0003/\n",
        "'''\n",
        "\n",
        "dir_start_index = 0\n",
        "subdir_start_index = 0\n",
        "'''\n",
        "Dataset folders:\n",
        "  basements\n",
        "  bathrooms\n",
        "  cafe\n",
        "  dining rooms\n",
        "  libraries\n",
        "  study rooms\n",
        "'''\n",
        "for d in range(dir_start_index, len(dirs)):\n",
        "    subdirs = glob.glob(dirs[d]+\"*/\")\n",
        "    subdirs.sort(key=natural_keys)\n",
        "\n",
        "    subdirs_len = len(subdirs)\n",
        "    subdirs_counter = 1\n",
        "    for s in range(subdir_start_index, len(subdirs)):\n",
        "        print(str(subdirs_counter) +\"/\"+str(subdirs_len) + \"\\n\" + subdirs[s] + \"\\nReading...\")\n",
        "        xfiles = glob.glob(subdirs[s]+\"*.png\")\n",
        "        xfiles.sort(key=natural_keys)\n",
        "\n",
        "        # counters of pairwise depth and color images\n",
        "        bad_count = 0\n",
        "        ok_count = 0\n",
        "        color_images = []\n",
        "        depth_images = []\n",
        "        xfiles_len = len(xfiles)\n",
        "        xfiles_counter = 0\n",
        "\n",
        "        out = display(progress(0, 100), display_id=True)\n",
        "        for f in xfiles:\n",
        "            # depth images path assemble\n",
        "            tmp = f.split(\"/\")\n",
        "            tmp[6] = \"Depth\"\n",
        "            d_f = '/'.join(tmp)\n",
        "\n",
        "            # not all color images have depth accordance in original dataset\n",
        "            if not os.path.exists(d_f):\n",
        "                bad_count = bad_count + 1\n",
        "            else:\n",
        "                ok_count = ok_count +1\n",
        "\n",
        "                # color image 1/2 of original size\n",
        "                color_images.append(read_and_resize(f, False, fx=0.5, fy=0.5))\n",
        "                # depth image 1/8 of original size\n",
        "                depth_images.append(read_and_resize(d_f, True, fx=0.0625, fy=0.0625))\n",
        "\n",
        "            xfiles_counter += 1\n",
        "            percent = xfiles_counter / xfiles_len * 100\n",
        "            out.update(progress(percent, 100))\n",
        "\n",
        "        subdirs_counter += 1\n",
        "\n",
        "        # Read statistics of bad and good pairs\n",
        "        print(\"Data reading result:\")\n",
        "        print(str(bad_count)+\" images without depth pair\")\n",
        "        print(str(ok_count)+\" full pairs\")\n",
        "\n",
        "        color_images_n = np.array(np.float32(color_images) / 255)\n",
        "        depth_images_n = np.array(depth_images)\n",
        "        # X_data - train feature vector\n",
        "        # Y_data - train labels image\n",
        "        print(\"X_data:\\n\"+str(color_images_n.shape))\n",
        "        print(\"Y_data:\\n\"+str(depth_images_n.shape))\n",
        "\n",
        "        \n",
        "        # Data augmentation\n",
        "        generator = ImageDataGenerator(rotation_range=5,\n",
        "                                       zoom_range=[1.0, 1.5],\n",
        "                                       horizontal_flip=True,\n",
        "                                       validation_split=0.2,\n",
        "                                       )\n",
        "        generator.fit(color_images_n)\n",
        "        \n",
        "        # model build\n",
        "        model.compile(optimizer=Nadam(1e-2),\n",
        "                      loss=MeanAbsoluteError(),\n",
        "                      metrics=['accuracy'])\n",
        "        \n",
        "        # model training\n",
        "        model.fit(generator.flow([color_images_n, color_images_n],\n",
        "                                 depth_images_n,\n",
        "                                 batch_size=128),\n",
        "                  validation_data=generator.flow([color_images_n, color_images_n],\n",
        "                                                 depth_images_n,\n",
        "                                                 batch_size=128,\n",
        "                                                 subset='validation'),\n",
        "                  steps_per_epoch=len(color_images_n) / 128,\n",
        "                  epochs=300,\n",
        "                  verbose=2,\n",
        "                  batch_size=128, )\n",
        "        \n",
        "        # model is saved after each subdirectories iteration\n",
        "        print(\"Saving model...\")\n",
        "        model.save('/content/gdrive/MyDrive/Model/CF_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2EsQVLjfTEX"
      },
      "source": [
        "model = load_model('/content/gdrive/MyDrive/Model/CF_model.h5')\n",
        "\n",
        "s = \"/content/gdrive/MyDrive/DATASET/Test/Images/study_rooms/study_room_0007/\"\n",
        "\n",
        "print(s + \"\\nReading...\")\n",
        "xfiles = glob.glob(s + \"*.png\")\n",
        "xfiles.sort(key=natural_keys)\n",
        "\n",
        "# counters of pairwise depth and color images\n",
        "count = 0\n",
        "ok_count = 0\n",
        "color_images = []\n",
        "depth_images = []\n",
        "xfiles_len = len(xfiles)\n",
        "xfiles_counter = 0\n",
        "\n",
        "for f in xfiles:\n",
        "    # depth images path assemble\n",
        "    tmp = f.split(\"/\")\n",
        "    tmp[6] = \"Depth\"\n",
        "    d_f = '/'.join(tmp)\n",
        "\n",
        "    # not all color images have depth accordance in original dataset\n",
        "    if not os.path.exists(d_f):\n",
        "        count = count + 1\n",
        "    else:\n",
        "        ok_count = ok_count +1\n",
        "\n",
        "        # color image 1/2 of original size\n",
        "        color_images.append(read_and_resize(f, False, fx=0.5, fy=0.5))\n",
        "\n",
        "        # color image 1/8 of original size\n",
        "        depth_images.append(read_and_resize(d_f, True, fx=0.0625, fy=0.0625))\n",
        "    xfiles_counter += 1\n",
        "    percent = xfiles_counter / xfiles_len * 100\n",
        "    out = display(progress(0, 100), display_id=True) \n",
        "    out.update(progress(percent, 100))\n",
        "\n",
        "# Read statistics of bad and good pairs\n",
        "print(\"Data reading result:\")\n",
        "print(str(count)+\" images without depth pair\")\n",
        "print(str(ok_count)+\" full pairs\")\n",
        "\n",
        "color_images_n = np.array(color_images)\n",
        "depth_images_n = np.array(depth_images)\n",
        "\n",
        "\n",
        "# X_data - test feature vector\n",
        "# Y_data - test labels image\n",
        "print(\"X_data:\\n\"+str(color_images_n.shape))\n",
        "print(\"Y_data:\\n\"+str(depth_images_n.shape))\n",
        "\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate([color_images_n, color_images_n], depth_images_n, batch_size=128)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "predictions = model.predict([color_images_n, color_images_n])\n",
        "print(predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}